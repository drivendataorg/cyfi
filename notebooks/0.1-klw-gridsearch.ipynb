{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f145bc-b67b-4897-86c7-417d22457f0f",
   "metadata": {},
   "source": [
    "Use gridsearch to see if there are more optimal lightGBM parameters we should be using.\n",
    "\n",
    "We'll use the features that a have already been generated for our current best experiment (third sentinel + land cover features, trained with folds). Compare the results to that [best experiment](https://docs.google.com/presentation/d/1zWrSMSivxylx_iH_aOapJfyziRsDuyuXOELduOn6x3c/edit#slide=id.g278eb39bdd6_0_43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6860759-8542-4b72-94f1-eb44f57a3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "050a2885-fe33-4992-9d0b-73018e1b15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from cloudpathlib import AnyPath\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from cyano.data.utils import add_unique_identifier\n",
    "from cyano.experiment.experiment import ExperimentConfig\n",
    "from cyano.pipeline import CyanoModelPipeline\n",
    "from cyano.settings import RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a8bd78-ce2f-4cea-80a0-5c65ab2f6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = AnyPath(\"tmp_dir\")\n",
    "tmp_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b72dfa71-e43d-4ec1-9405-a1dbc2254808",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = AnyPath(\n",
    "    \"s3://drivendata-competition-nasa-cyanobacteria/experiments/results/third_sentinel_with_folds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c358c44b-51e8-4bdb-9013-73d8fac278ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AOT_mean</th>\n",
       "      <th>AOT_min</th>\n",
       "      <th>AOT_max</th>\n",
       "      <th>AOT_range</th>\n",
       "      <th>B01_mean</th>\n",
       "      <th>B01_min</th>\n",
       "      <th>B01_max</th>\n",
       "      <th>B01_range</th>\n",
       "      <th>B02_mean</th>\n",
       "      <th>B02_min</th>\n",
       "      <th>...</th>\n",
       "      <th>WVP_min</th>\n",
       "      <th>WVP_max</th>\n",
       "      <th>WVP_range</th>\n",
       "      <th>NDVI_B04</th>\n",
       "      <th>NDVI_B05</th>\n",
       "      <th>NDVI_B06</th>\n",
       "      <th>NDVI_B07</th>\n",
       "      <th>month</th>\n",
       "      <th>days_before_sample</th>\n",
       "      <th>land_cover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001cfa683171fe80161cdbe6a090c94</th>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.843750</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>441.956349</td>\n",
       "      <td>146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>0.581754</td>\n",
       "      <td>0.418335</td>\n",
       "      <td>0.114064</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001cfa683171fe80161cdbe6a090c94</th>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>435.984375</td>\n",
       "      <td>229.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>503.288549</td>\n",
       "      <td>154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>167.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>0.418914</td>\n",
       "      <td>0.120972</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001cfa683171fe80161cdbe6a090c94</th>\n",
       "      <td>204.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>902.640625</td>\n",
       "      <td>703.0</td>\n",
       "      <td>1661.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>938.553288</td>\n",
       "      <td>672.0</td>\n",
       "      <td>...</td>\n",
       "      <td>931.0</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455419</td>\n",
       "      <td>0.329302</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.027511</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001cfa683171fe80161cdbe6a090c94</th>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>518.484375</td>\n",
       "      <td>316.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>618.096939</td>\n",
       "      <td>277.0</td>\n",
       "      <td>...</td>\n",
       "      <td>574.0</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>0.548216</td>\n",
       "      <td>0.391690</td>\n",
       "      <td>0.115218</td>\n",
       "      <td>0.032818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001cfa683171fe80161cdbe6a090c94</th>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.218750</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>485.587302</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.582335</td>\n",
       "      <td>0.425137</td>\n",
       "      <td>0.129981</td>\n",
       "      <td>0.039196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  AOT_mean  AOT_min  AOT_max  AOT_range  \\\n",
       "sample_id                                                                 \n",
       "0001cfa683171fe80161cdbe6a090c94     102.0    102.0    102.0        0.0   \n",
       "0001cfa683171fe80161cdbe6a090c94     132.0    132.0    132.0        0.0   \n",
       "0001cfa683171fe80161cdbe6a090c94     204.0    204.0    204.0        0.0   \n",
       "0001cfa683171fe80161cdbe6a090c94     102.0    102.0    102.0        0.0   \n",
       "0001cfa683171fe80161cdbe6a090c94     102.0    102.0    102.0        0.0   \n",
       "\n",
       "                                    B01_mean  B01_min  B01_max  B01_range  \\\n",
       "sample_id                                                                   \n",
       "0001cfa683171fe80161cdbe6a090c94  319.843750    144.0   1083.0      939.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  435.984375    229.0   1055.0      826.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  902.640625    703.0   1661.0      958.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  518.484375    316.0   1554.0     1238.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  318.218750    104.0   1314.0     1210.0   \n",
       "\n",
       "                                    B02_mean  B02_min  ...  WVP_min  WVP_max  \\\n",
       "sample_id                                              ...                     \n",
       "0001cfa683171fe80161cdbe6a090c94  441.956349    146.0  ...    277.0   1413.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  503.288549    154.0  ...    167.0    828.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  938.553288    672.0  ...    931.0    931.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  618.096939    277.0  ...    574.0   1436.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  485.587302    162.0  ...    340.0   1114.0   \n",
       "\n",
       "                                  WVP_range  NDVI_B04  NDVI_B05  NDVI_B06  \\\n",
       "sample_id                                                                   \n",
       "0001cfa683171fe80161cdbe6a090c94     1136.0  0.581754  0.418335  0.114064   \n",
       "0001cfa683171fe80161cdbe6a090c94      661.0  0.574375  0.418914  0.120972   \n",
       "0001cfa683171fe80161cdbe6a090c94        0.0  0.455419  0.329302  0.097910   \n",
       "0001cfa683171fe80161cdbe6a090c94      862.0  0.548216  0.391690  0.115218   \n",
       "0001cfa683171fe80161cdbe6a090c94      774.0  0.582335  0.425137  0.129981   \n",
       "\n",
       "                                  NDVI_B07  month  days_before_sample  \\\n",
       "sample_id                                                               \n",
       "0001cfa683171fe80161cdbe6a090c94  0.033551    2.0                15.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  0.042572    3.0                 8.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  0.027511    3.0                 5.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  0.032818    2.0                13.0   \n",
       "0001cfa683171fe80161cdbe6a090c94  0.039196    2.0                10.0   \n",
       "\n",
       "                                  land_cover  \n",
       "sample_id                                     \n",
       "0001cfa683171fe80161cdbe6a090c94          11  \n",
       "0001cfa683171fe80161cdbe6a090c94          11  \n",
       "0001cfa683171fe80161cdbe6a090c94          11  \n",
       "0001cfa683171fe80161cdbe6a090c94          11  \n",
       "0001cfa683171fe80161cdbe6a090c94          11  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_csv(experiment_dir / \"features_train.csv\", index_col=0)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b28e3e6-217b-4da2-a8b0-caa8ceb2add8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17060, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train labels\n",
    "train = pd.read_csv(\n",
    "    AnyPath(\n",
    "        \"s3://drivendata-competition-nasa-cyanobacteria/experiments/splits/competition/train.csv\"\n",
    "    )\n",
    ")\n",
    "train = add_unique_identifier(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26d40ff2-2f22-4d41-b947-bb0796965e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>density_cells_per_ml</th>\n",
       "      <th>severity</th>\n",
       "      <th>distance_to_water_m</th>\n",
       "      <th>log_density</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d7ebbce63c7d1498cc627a1e77f6061c</th>\n",
       "      <td>aabm</td>\n",
       "      <td>Indiana State Department of Health</td>\n",
       "      <td>midwest</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.373320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0856c3740614b5ee606f82d6c3a215a0</th>\n",
       "      <td>aacd</td>\n",
       "      <td>N.C. Division of Water Resources N.C. Departme...</td>\n",
       "      <td>south</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1</td>\n",
       "      <td>514.0</td>\n",
       "      <td>5.673323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uid  \\\n",
       "sample_id                                \n",
       "d7ebbce63c7d1498cc627a1e77f6061c  aabm   \n",
       "0856c3740614b5ee606f82d6c3a215a0  aacd   \n",
       "\n",
       "                                                                      data_provider  \\\n",
       "sample_id                                                                             \n",
       "d7ebbce63c7d1498cc627a1e77f6061c                 Indiana State Department of Health   \n",
       "0856c3740614b5ee606f82d6c3a215a0  N.C. Division of Water Resources N.C. Departme...   \n",
       "\n",
       "                                   region   latitude  longitude        date  \\\n",
       "sample_id                                                                     \n",
       "d7ebbce63c7d1498cc627a1e77f6061c  midwest  39.080319 -86.430867  2018-05-14   \n",
       "0856c3740614b5ee606f82d6c3a215a0    south  35.875083 -78.878434  2020-11-19   \n",
       "\n",
       "                                  density_cells_per_ml  severity  \\\n",
       "sample_id                                                          \n",
       "d7ebbce63c7d1498cc627a1e77f6061c                 585.0         1   \n",
       "0856c3740614b5ee606f82d6c3a215a0                 290.0         1   \n",
       "\n",
       "                                  distance_to_water_m  log_density  \n",
       "sample_id                                                           \n",
       "d7ebbce63c7d1498cc627a1e77f6061c                  0.0     6.373320  \n",
       "0856c3740614b5ee606f82d6c3a215a0                514.0     5.673323  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "321297a1-f2e0-4c12-907f-34e91cb538d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_id\n",
       "0001cfa683171fe80161cdbe6a090c94    15.800642\n",
       "0001cfa683171fe80161cdbe6a090c94    15.800642\n",
       "0001cfa683171fe80161cdbe6a090c94    15.800642\n",
       "0001cfa683171fe80161cdbe6a090c94    15.800642\n",
       "0001cfa683171fe80161cdbe6a090c94    15.800642\n",
       "                                      ...    \n",
       "fff76b0c751a22eda5a33f3f0d7fda98    10.338188\n",
       "fff948d10c4ef9e03fddb358140b2755     9.275660\n",
       "fff948d10c4ef9e03fddb358140b2755     9.275660\n",
       "fff948d10c4ef9e03fddb358140b2755     9.275660\n",
       "fff948d10c4ef9e03fddb358140b2755     9.275660\n",
       "Name: log_density, Length: 43409, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train_features.index].log_density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15856a50-adb5-4d88-9021-83b19d03e92b",
   "metadata": {},
   "source": [
    "Try params from each of the winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0ffcde8-eb75-46dd-9344-8cc093a7859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [-1, 8],\n",
    "    # 'num_leaves': [31],\n",
    "    # 'learning_rate': [0.005, 0.1],\n",
    "    # 'bagging_fraction': [0.3, 1.0],\n",
    "    # 'feature_fraction': [0.3, 1.0],\n",
    "    'min_split_gain': [0.0, 0.1],\n",
    "    # 'n_estimators': [1000, 100000, 470], # same as num_boost_round\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b163b1bd-92a5-4ccf-8091-a3fe2f40fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor(objective='regression', metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0fd2a0f4-94db-44ee-a889-45b7632baaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator = lgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='r2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f1c31f8-62b8-4d1e-9d96-f6c7239f415e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15445\n",
      "[LightGBM] [Info] Number of data points in the train set: 43409, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.858860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [-1, 8], &#x27;min_split_gain&#x27;: [0.0, 0.1]},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [-1, 8], &#x27;min_split_gain&#x27;: [0.0, 0.1]},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LGBMRegressor(metric='rmse', objective='regression'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [-1, 8], 'min_split_gain': [0.0, 0.1]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.109536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.100747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(\n",
    "    train_features,\n",
    "    train.loc[train_features.index].log_density\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b374a2b-dad8-46ff-ba4a-404f3429eeac",
   "metadata": {},
   "source": [
    "If we don't specify 'scoring' in `grid_search`, I think score is the `lgb_model.score` method, which is R^2. Unclear whether specifying `metric=\"rmse\"` makes the score that is returned RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f2c123e-9b87-4deb-8491-1454cdc28d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_split_gain</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.611209</td>\n",
       "      <td>1.878887</td>\n",
       "      <td>0.067850</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'max_depth': 8, 'min_split_gain': 0.1}</td>\n",
       "      <td>0.527846</td>\n",
       "      <td>0.490092</td>\n",
       "      <td>0.533387</td>\n",
       "      <td>0.521765</td>\n",
       "      <td>0.514624</td>\n",
       "      <td>0.517542</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.263181</td>\n",
       "      <td>0.500616</td>\n",
       "      <td>0.039015</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'max_depth': 8, 'min_split_gain': 0.0}</td>\n",
       "      <td>0.527846</td>\n",
       "      <td>0.490092</td>\n",
       "      <td>0.533387</td>\n",
       "      <td>0.521765</td>\n",
       "      <td>0.514624</td>\n",
       "      <td>0.517542</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.913565</td>\n",
       "      <td>2.236077</td>\n",
       "      <td>0.071177</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'max_depth': -1, 'min_split_gain': 0.0}</td>\n",
       "      <td>0.533259</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>0.535176</td>\n",
       "      <td>0.523156</td>\n",
       "      <td>0.517355</td>\n",
       "      <td>0.520896</td>\n",
       "      <td>0.014266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.165612</td>\n",
       "      <td>4.943512</td>\n",
       "      <td>0.052979</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'max_depth': -1, 'min_split_gain': 0.1}</td>\n",
       "      <td>0.533259</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>0.535176</td>\n",
       "      <td>0.523156</td>\n",
       "      <td>0.517831</td>\n",
       "      <td>0.520991</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       4.611209      1.878887         0.067850        0.022124   \n",
       "2      12.263181      0.500616         0.039015        0.001223   \n",
       "0      24.913565      2.236077         0.071177        0.018261   \n",
       "1      20.165612      4.943512         0.052979        0.015319   \n",
       "\n",
       "  param_max_depth param_min_split_gain  \\\n",
       "3               8                  0.1   \n",
       "2               8                  0.0   \n",
       "0              -1                  0.0   \n",
       "1              -1                  0.1   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "3   {'max_depth': 8, 'min_split_gain': 0.1}           0.527846   \n",
       "2   {'max_depth': 8, 'min_split_gain': 0.0}           0.527846   \n",
       "0  {'max_depth': -1, 'min_split_gain': 0.0}           0.533259   \n",
       "1  {'max_depth': -1, 'min_split_gain': 0.1}           0.533259   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.490092           0.533387           0.521765           0.514624   \n",
       "2           0.490092           0.533387           0.521765           0.514624   \n",
       "0           0.495535           0.535176           0.523156           0.517355   \n",
       "1           0.495535           0.535176           0.523156           0.517831   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.517542        0.015080                3  \n",
       "2         0.517542        0.015080                3  \n",
       "0         0.520896        0.014266                2  \n",
       "1         0.520991        0.014244                1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with scoring specified in grid_search\n",
    "pd.DataFrame(grid_search.cv_results_).sort_values(by='mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95794039-b565-44b1-9921-13e22d180e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_split_gain</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.269762</td>\n",
       "      <td>0.703575</td>\n",
       "      <td>0.025750</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'max_depth': 8, 'min_split_gain': 0.1}</td>\n",
       "      <td>0.527846</td>\n",
       "      <td>0.490092</td>\n",
       "      <td>0.533387</td>\n",
       "      <td>0.521765</td>\n",
       "      <td>0.514624</td>\n",
       "      <td>0.517542</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.715456</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.029753</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'max_depth': 8, 'min_split_gain': 0.0}</td>\n",
       "      <td>0.527846</td>\n",
       "      <td>0.490092</td>\n",
       "      <td>0.533387</td>\n",
       "      <td>0.521765</td>\n",
       "      <td>0.514624</td>\n",
       "      <td>0.517542</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.342626</td>\n",
       "      <td>0.529544</td>\n",
       "      <td>0.030479</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'max_depth': -1, 'min_split_gain': 0.0}</td>\n",
       "      <td>0.533259</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>0.535176</td>\n",
       "      <td>0.523156</td>\n",
       "      <td>0.517355</td>\n",
       "      <td>0.520896</td>\n",
       "      <td>0.014266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.221056</td>\n",
       "      <td>0.384248</td>\n",
       "      <td>0.026779</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'max_depth': -1, 'min_split_gain': 0.1}</td>\n",
       "      <td>0.533259</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>0.535176</td>\n",
       "      <td>0.523156</td>\n",
       "      <td>0.517831</td>\n",
       "      <td>0.520991</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       2.269762      0.703575         0.025750        0.001052   \n",
       "2       3.715456      0.167349         0.029753        0.006178   \n",
       "0       4.342626      0.529544         0.030479        0.005983   \n",
       "1       4.221056      0.384248         0.026779        0.001072   \n",
       "\n",
       "  param_max_depth param_min_split_gain  \\\n",
       "3               8                  0.1   \n",
       "2               8                  0.0   \n",
       "0              -1                  0.0   \n",
       "1              -1                  0.1   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "3   {'max_depth': 8, 'min_split_gain': 0.1}           0.527846   \n",
       "2   {'max_depth': 8, 'min_split_gain': 0.0}           0.527846   \n",
       "0  {'max_depth': -1, 'min_split_gain': 0.0}           0.533259   \n",
       "1  {'max_depth': -1, 'min_split_gain': 0.1}           0.533259   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "3           0.490092           0.533387           0.521765           0.514624   \n",
       "2           0.490092           0.533387           0.521765           0.514624   \n",
       "0           0.495535           0.535176           0.523156           0.517355   \n",
       "1           0.495535           0.535176           0.523156           0.517831   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "3         0.517542        0.015080                3  \n",
       "2         0.517542        0.015080                3  \n",
       "0         0.520896        0.014266                2  \n",
       "1         0.520991        0.014244                1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without scoring specified in grid_search\n",
    "pd.DataFrame(grid_search.cv_results_).sort_values(by='mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6bcf4a60-6396-4bcc-8fa5-a7f05b20cd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RegressorMixin.score of LGBMRegressor(eval_metric='rmse', objective='regression')>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39c2368c-9f6b-4eff-826b-62e9b5b5f39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return the coefficient of determination of the prediction.\n",
       "\n",
       "The coefficient of determination :math:`R^2` is defined as\n",
       ":math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
       "sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
       "is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
       "The best possible score is 1.0 and it can be negative (because the\n",
       "model can be arbitrarily worse). A constant model that always predicts\n",
       "the expected value of `y`, disregarding the input features, would get\n",
       "a :math:`R^2` score of 0.0.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : array-like of shape (n_samples, n_features)\n",
       "    Test samples. For some estimators this may be a precomputed\n",
       "    kernel matrix or a list of generic objects instead with shape\n",
       "    ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
       "    is the number of samples used in the fitting for the estimator.\n",
       "\n",
       "y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "    True values for `X`.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "score : float\n",
       "    :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
       "``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
       "with default value of :func:`~sklearn.metrics.r2_score`.\n",
       "This influences the ``score`` method of all the multioutput\n",
       "regressors (except for\n",
       ":class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/anaconda3/envs/withherbie/lib/python3.10/site-packages/sklearn/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?lgb_model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "accbc33e-671c-40cc-8885-f8636345fb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__boosting_type': 'gbdt',\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__colsample_bytree': 1.0,\n",
       " 'estimator__importance_type': 'split',\n",
       " 'estimator__learning_rate': 0.1,\n",
       " 'estimator__max_depth': -1,\n",
       " 'estimator__min_child_samples': 20,\n",
       " 'estimator__min_child_weight': 0.001,\n",
       " 'estimator__min_split_gain': 0.0,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__num_leaves': 31,\n",
       " 'estimator__objective': 'regression',\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__reg_alpha': 0.0,\n",
       " 'estimator__reg_lambda': 0.0,\n",
       " 'estimator__subsample': 1.0,\n",
       " 'estimator__subsample_for_bin': 200000,\n",
       " 'estimator__subsample_freq': 0,\n",
       " 'estimator__eval_metric': 'rmse',\n",
       " 'estimator': LGBMRegressor(eval_metric='rmse', objective='regression'),\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'max_depth': [-1, 8], 'min_split_gain': [0.0, 0.1]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cff5ce5-06b6-4114-8936-5079309daea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.1,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'regression',\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'eval_metric': 'rmse'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15436\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.878464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15439\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.840375\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34728, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15437\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.861643\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15435\n",
      "[LightGBM] [Info] Number of data points in the train set: 34727, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score 10.852245\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf4c94a4-9506-4919-857a-66509db706c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_data = lgb.Dataset(\n",
    "    train_features,\n",
    "    train.loc[train_features.index].log_density,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f9c76-3991-4b18-bf31-3ef0624d0b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a376a6-043f-4e7f-aa43-e20e79c3516d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
